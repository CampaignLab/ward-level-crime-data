{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a crime count by ward dataframe and check for statisically significant relationships between changes in crime rate and change in labour vote share\n",
    "\n",
    "This notebook imports json crime data from Jan 2016 to May 2018. The data exists in the github repository and has been pre-labeled with date and ward code.\n",
    "\n",
    "The notebook aggregates the crime counts, reads a csv file (in repository) for the labour vote change in each ward between the 2014 and 2018 council elections and combines the results in a dataframe.\n",
    "\n",
    "Ultimately no statistically significant relationship was found between changes in crime count and change in Labour vote share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "import os\n",
    "from pathlib import Path\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect all the paths of the files we want\n",
    "# pathlib lets you use * as many times as you want in the glob\n",
    "root_data_path = Path('../2018-05 boundaries/')\n",
    "# we can use the glob function to restrict json files to specific date ranges\n",
    "fnames = list(map(lambda x : str(x), list(root_data_path.glob('london_month_*/*.json'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fnames = a list of all the json filenames\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ward_code</th>\n",
       "      <th>month</th>\n",
       "      <th>crime_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ward_code, month, crime_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each json file holds records for all crimes that occurred in each ward each month\n",
    "# The length of the json reflects how many crimes occurred in that ward in that month\n",
    "# We run through the jsons keeping a count of how crimes occurred in each ward in each month\n",
    "count_dictionary = {}\n",
    "\n",
    "for fname in fnames:\n",
    "    with open(fname) as json_file:\n",
    "        try:\n",
    "            data = json.load(json_file)\n",
    "            ward = fname.split('_')[-2]\n",
    "            month = '-'.join(fname.split('_')[-5:-3])\n",
    "            crimes = len(data) # len(data) = number of crimes recorded in the file\n",
    "            key = ward + '_' + month\n",
    "            count_dictionary[key] = count_dictionary.get(key, 0) + len(data)\n",
    "        except:\n",
    "            pass\n",
    "#             print(data, '\\n\\n')\n",
    "\n",
    "# At this point we have created a dictionary where there is a key made of ward code and year-month\n",
    "# The value associated with each key is the number of crimes that occurred in the corresponding ward in each month\n",
    "\n",
    "final_csv = '' # Take all of the keys and values and write them to a csv file\n",
    "for k, v in count_dictionary.items():\n",
    "    final_csv += ','.join(k.split('_'))\n",
    "    final_csv += ',' + str(v) + '\\n'\n",
    "\n",
    "\n",
    "text_file = open(\"../crimes_by_ward_by_month.csv\", \"w\")\n",
    "text_file.write(final_csv)\n",
    "text_file.close()\n",
    "\n",
    "df_monthly = pd.read_csv(\"../crimes_by_ward_by_month.csv\", names =['ward_code', 'month', 'crime_count'])\n",
    "df_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['month'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bd09e7957a63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# combine the yearly dataframes to create one large dataframe containing all years\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mjoin_year_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_2016\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_2017\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mjoin_year_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_year_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_2018\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   4667\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4668\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 4669\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   4670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4671\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   4682\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[1;32m   4683\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4684\u001b[0;31m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[1;32m   4685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4686\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m     52\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                          copy=copy, indicator=indicator)\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         llabels, rlabels = items_overlap_with_suffix(ldata.items, lsuf,\n\u001b[0;32m--> 575\u001b[0;31m                                                      rdata.items, rsuf)\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mlindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mleft_indexer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mitems_overlap_with_suffix\u001b[0;34m(left, lsuffix, right, rsuffix)\u001b[0m\n\u001b[1;32m   4699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4700\u001b[0m             raise ValueError('columns overlap but no suffix specified: %s' %\n\u001b[0;32m-> 4701\u001b[0;31m                              to_rename)\n\u001b[0m\u001b[1;32m   4702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4703\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlrenamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['month'], dtype='object')"
     ]
    }
   ],
   "source": [
    "# Splitting the columns to create yearly dataframes that only look at q1\n",
    "df_2016 = df_monthly[(df_monthly[\"month\"]<\"2016-04\") & (df_monthly[\"month\"]>\"2015-12\")].groupby(\"ward_code\").sum()\n",
    "df_2017 = df_monthly[(df_monthly[\"month\"]<\"2017-04\") & (df_monthly[\"month\"]>\"2016-12\")].groupby(\"ward_code\").sum()\n",
    "df_2018 = df_monthly[(df_monthly[\"month\"]<\"2018-04\") & (df_monthly[\"month\"]>\"2017-12\")].groupby(\"ward_code\").sum()\n",
    "\n",
    "df_2016.rename(columns={'crime_count':'crimes2016q1'}, inplace=True)\n",
    "df_2017.rename(columns={'crime_count':'crimes2017q1'}, inplace=True)\n",
    "df_2018.rename(columns={'crime_count':'crimes2018q1'}, inplace=True)\n",
    "\n",
    "# combine the yearly dataframes to create one large dataframe containing all years\n",
    "join_year_df = df_2016.join(df_2017)\n",
    "join_year_df = join_year_df.join(df_2018)\n",
    "\n",
    "# Create a new column that records the change in crime rate between q1 2017 and q1 2018\n",
    "join_year_df['crime_change_q1_2017-18percent'] = ((join_year_df['crimes2018q1'] - \\\n",
    "                                           join_year_df['crimes2017q1'])/join_year_df['crimes2017q1'])*100\n",
    "join_year_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ward_vote_change = pd.read_csv('../crimeChangeByWard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns that look at all quarters\n",
    "# Splitting the columns to create yearly dataframes\n",
    "# Because we only have data up to May 2018 we cannot compare it to previous years\n",
    "df_2016 = df_monthly[(df_monthly[\"month\"]<\"2017-01\") & (df_monthly[\"month\"]>\"2015-12\")].groupby(\"ward_code\").sum()\n",
    "df_2017 = df_monthly[(df_monthly[\"month\"]<\"2018-01\") & (df_monthly[\"month\"]>\"2016-12\")].groupby(\"ward_code\").sum()\n",
    "df_2018 = df_monthly[(df_monthly[\"month\"]<\"2019-01\") & (df_monthly[\"month\"]>\"2017-12\")].groupby(\"ward_code\").sum()\n",
    "\n",
    "df_2016.rename(columns={'crime_count':'totalcrimes2016'}, inplace=True)\n",
    "df_2017.rename(columns={'crime_count':'totalcrimes2017'}, inplace=True)\n",
    "df_2018.rename(columns={'crime_count':'totalcrimes2018'}, inplace=True)\n",
    "\n",
    "join_year_df = join_year_df.join(df_2016)\n",
    "join_year_df = join_year_df.join(df_2017)\n",
    "join_year_df = join_year_df.join(df_2018)\n",
    "join_year_df['crime_change_2016-17percent'] = ((join_year_df['totalcrimes2017'] - \\\n",
    "                                         join_year_df['totalcrimes2016'])/join_year_df['totalcrimes2016'])*100\n",
    "join_year_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ward_vote_change.rename(columns={'WardID': 'ward_code', 'Percent change': 'Labour vote change 2014-18percent'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ward_vote_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.set_index('key').join(other.set_index('key'))\n",
    "final_df = df_ward_vote_change.set_index('ward_code').join(join_year_df)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(final_df['totalcrimes2017'].isnull()) # Check how many wards are missing crime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv('../CrimeByWard-LabourVoteChange.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix shows some weak correlation in relationships: \n",
    "Wards with higher crime rates were more likely to swing towards Labour\n",
    "Wards where the crime rate increased (looking at either the change between 2016/17 or comparing q1 2017 with q1 2018) swung away from Labour. We still need to assess whether these correlations are statistically significant (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True) # drop wards we have no crime data for\n",
    "print(final_df.shape)\n",
    "target = final_df['Labour vote change 2014-18percent']\n",
    "variables = final_df[['crime_change_q1_2017-18percent']].copy()\n",
    "\n",
    "variables = sm.add_constant(variables) # Adds a column called 'const' that is all 1s (in order to provide a coeficient for the constant)\n",
    "crime_model = sm.OLS(target, variables)\n",
    "results = crime_model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation of linear regression model\n",
    "Our best estimate for how crime effects vote swing is that a 1% increase in crime causes a decrease in vote share of 0.03% but there is a probability of 21.% chance that we observed this relationship by chance (and in fact there is no relationship). It does not pass the test for statisical significance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATING THE DATA CREATED BY JSON WITH DATA CREATED USING LUKA'S PANDAS SCRIPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code compares the values from the pandas dataframe (containing all individual crimes)\n",
    "# findings were that 3 out of 482 had different crime counts for 2017 and 2016\n",
    "# Not sure what caused this discrepancy but it's sufficently small to ignore.\n",
    "\n",
    "# This is a large pandas dataframe that contains a row for every individual recorded crime\n",
    "# It was created using a different method to the counting method above\n",
    "# We are using it here to validate the final_df which was created in the code above\n",
    "# lukadf = pd.read_csv('../2018-05.csv')\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# wards = final_df.index.values\n",
    "# errors = 0\n",
    "# for i in tqdm(range(len(final_df))):\n",
    "#     ward = wards[i]\n",
    "#     luka_crime_count = sum((lukadf.loc[:,'ward'] == ward) & (lukadf['month']>='2017-01') & (lukadf['month']<'2018-01'))\n",
    "#     if final_df.loc[ward, 'totalcrimes2017'] != luka_crime_count:\n",
    "#         errors += 1\n",
    "#         print(final_df.loc[ward, 'totalcrimes2017'] - luka_crime_count)\n",
    "        \n",
    "    \n",
    "# print('errors', errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
